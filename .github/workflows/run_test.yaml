name: "Perf Test"
on:
  workflow_dispatch:
    inputs:
      reset-results:
        description: |
          If set to true, the results will be reset and the previous results will overwritten.
        required: false
        default: 'false'
      test-duration:
        description: |
          The duration of the test in seconds.
        required: false
        default: '60s'
        options:
          - '15s'
          - '30s'
          - '60s'
          - '120s'
      docker-compose-file:
        description: |
          The docker-compose file to use.
        required: false
        default: 'docker-compose.yml'
        options:
          - 'docker-compose.yml'
          - 'docker-compose-tmp-mounted.yml'
      chroma-version:
        description: |
          The version of Chroma to test.
        required: false
        default: 'main'

permissions:
  contents: read

jobs:
  test:
    name: "Performance Test ${{ matrix.dataset }}"
    timeout-minutes: 240
    strategy:
      matrix:
        dataset:  ["testds-100k","testds-250k","testds-500k", "testds-1M","testds-5M"] #[ "chroma-perf-100k", "chroma-perf-250k", "chroma-perf-500k", "chroma-perf-1M" ]
#        chroma_version: ["0.5.0","main"]
#        config: ["docker","cli"]
    runs-on: chroma
    # Use the Bash shell regardless whether the GitHub Actions runner is ubuntu-latest, macos-latest, or windows-latest
    defaults:
      run:
        shell: bash

    steps:
      # Checkout the repository to the GitHub Actions runner
      - name: Checkout
        uses: actions/checkout@v3
#      - name: Set up Python 3.11
#        uses: actions/setup-python@v2
#        with:
#          python-version: "3.11"
      - name: Setup Poetry
        run: |
          set -e
          curl -sSL https://install.python-poetry.org | python3 -
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: eu-west-1 # configurable
      - name: Clone Chroma Repo
        run: |
          set -e
          rm -rf chroma # remove the existing repo
          git clone -b ${{ github.event.inputs.chroma-version }} https://github.com/chroma-core/chroma.git
      - name: Pull dataset
        run: |
          set -e
          aws s3 cp s3://chroma-perf-datasets/${{ matrix.dataset }}.tar.gz .
          mkdir -p ./chroma-data
          tar -xvf ${{ matrix.dataset }}.tar.gz -C ./chroma-data/ --strip-components=1
          tree ./chroma-data/
      - name: Pull result set
        if: ${{ github.event.inputs.reset-results == 'false' }}
        run: |
          set -e
          if aws s3 ls s3://chroma-perf-results/results.tar.gz ; then
            aws s3 cp s3://chroma-perf-results/results.tar.gz .
            tar -xvf results.tar.gz
          else
            echo "File does not exist, skipping download and extraction."
          fi
      - name: Docker compose
        run: |
          set -e
          docker compose -f ${{ github.event.inputs.docker-compose-file }} up -d --build
      - name: Install dependencies
        run: |
          set -e
          export PATH="$HOME/.local/bin:$PATH" #hacky but works
          poetry update
      - name: Verify Data and Warmup
        run: |
          set -e
          curl -v http://localhost:8000/api/v1
          curl -v http://localhost:8000/api/v1/collections
          COLLECTION_ID=$(curl -v http://localhost:8000/api/v1/collections | jq -r '.[0].id')
          [[ -z "$COLLECTION_ID" ]] && exit 1
          echo "Warming up with a query"
          curl -X 'POST' \
            "http://localhost:8000/api/v1/collections/${COLLECTION_ID}" \
            -H 'accept: application/json' \
            -d '{"include":["embeddings"],"limit":1}'
      - name: Run tests
        run: |
          set -e
          export PATH="$HOME/.local/bin:$PATH" #hacky but works
          echo "Running perf tests"
          rm -rf ./results/
          mkdir -p ./results/
          poetry run python perf_test/run_perf_test.py --queries-file ./chroma-data/queries.jsonl --output-path ./results/
        env:
          PERF_TEST_DURATION: ${{ github.event.inputs.test-duration }}
          PERF_TEST_DATASET: ${{ matrix.dataset }}
          PERF_TEST_RUN_ID: ${{ github.run_id }}
          CHROMA_CONFIG_ID: ${{ github.event.input.docker-compose-file }}
      - name: Upload results to S3
        run: |
          set -e
          tar -zcvf results.tar.gz merged_locust_data.parquet
          aws s3 cp results.tar.gz s3://chroma-perf-results/results.tar.gz
      - name: Upload results artifact
        uses: actions/upload-artifact@v2
        with:
          name: results
          path: results.tar.gz
      - name: Merge results
        if: false
        run: |
          set -e
          export PATH="$HOME/.local/bin:$PATH" #hacky but works
          echo "Merging results"
          poetry run python perf_test/merge_results.py --queries-file ./chroma-data/queries.jsonl --results-dir ./results/ --dataset-name ${{ matrix.dataset }}
      - name: Generate Graphs
        if: false
        run: |
          set -e
          export PATH="$HOME/.local/bin:$PATH" #hacky but works
          echo "Generating graphs"
          poetry run python perf_test/generate_graphs.py --results-dir ./results/ --results-file ./results/${{ matrix.dataset }}_merged_locust_data.parquet
      - name: Cleanup docker compose
        if: always()
        run: |
          set -e
          sudo rm -rf ./chroma-data
          sudo rm -rf ./chroma
          rm -rf ./results
          rm -rf results.tar.gz
          rm -rf merged_locust_data.parquet
          docker compose -f ${{ github.event.inputs.docker-compose-file }} down --volumes
